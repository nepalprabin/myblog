{
  "hash": "b0e543b78962f2067f2cbdfb96830e96",
  "result": {
    "markdown": "---\ncategories:\n  - machine-learning\n  - NLP\n  - deep-learning\ndate: \"2023-03-05\"\ntitle: Brief overview of GPT-4\ndraft: true\n---\n\n::: {.cell .column-screen-inset layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](../../../../../images/gpt-4_mock_design.jpeg){fig-align='center' width=200}\n:::\n\n::: {.cell-output-display}\n![](../../../../../images/gpt-4_website.png){fig-align='center' width=200}\n:::\n:::\n\n\nSince the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural language processing communities regarding its capabilities.\nIn addition to this, ChatGPT has captured the attention of the internet at large due to its remarkable ability to generate fluent and natural-sounding responses across a wide range of prompts and language tasks.\nDue to this, it became fastest growing consumer application in the history, just two months after the launch. ChatGPT is fine-tuned from a model in the GPT-3.5 series and can write articles, jokes, poetrys in response to the prompt.\nThough powerful, there have also been concerns raised about the potential risks associated with it and other large language models (LLMs), particularly with respect to issues such as bias, and misinformation. One of the major concern for LLMs\nis that it suffers from <code>hallucination</code>.\n\n<blockquote>\nHallucination refers to the phenomenon where the model generates responses that are not supported by the input or are inconsistent with reality.\nThis can happen when the model generates text that appears to be coherent and relevant, but is not grounded in any factual or contextual information.\n</blockquote>\n\nA year after releasing ChatGPT, OpenAI released GPT-4 (on 14th March, an improved version of GPT-3.5 model that supports multimodal data. It is capable of processing text and image data to generate textual data.\nIt achieved human level performance on various professional and academic benchmarks. On a simulated bar exam, GPT-4 achieved a score that falls on the top 10%\nof the exam takes. In contrast, the score achieved by previous model GPT-3.5 fell on bottom 10%. This shows the level of improvement achieved by the latest version of GPT.\nIt is also important to mention that the model was not specifically trained on these exams. A minority of problems were seen by model while training.\n\n## Capabilities of GPT-4\nA demo run by <code>Greg Brockman</code> (President and Co-founder, OpenAI) after the release of GPT-4 shows various capabilities of the model\n\n### 1. Hand-drawn pencil drawing turned into a fully functional website\nSince, GPT-4 model is multi-modal, we can provide image input and provide text prompts to get ouput. Below is the example where an website mock is provided \nin the paper and a prompt is given asking the model to generate the code to create a website that looks like the mock design. The generated output is mind blowing.\n\n![](/images/gpt-4_mock_design.jpeg)  ![](/images/gpt-4_website.png)  \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}